{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd35a37-a4b8-449f-bc49-5766f93abcb8",
   "metadata": {},
   "source": [
    "# 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554a1c21-bef7-4c44-8711-3e3ee719cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import collections\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aca604-9fb2-413b-a8ce-7761a3fa82af",
   "metadata": {},
   "source": [
    "# 2. Choose appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01594eb-5764-4719-bd51-c4adf091886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "gamma = 0.98\n",
    "buffer_limit = 50000\n",
    "batch_size = 32\n",
    "max_episodes = 30000  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f33876-9d97-4f32-b158-7f4957d2514b",
   "metadata": {},
   "source": [
    "# 3. Define the Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e081a29-37d8-46e7-b2a4-77d8574ac122",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "               torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a2aea-3d18-4ca2-8a6d-2f3158b7622e",
   "metadata": {},
   "source": [
    "# 4. Define the Q-Network for the MountainCar-v0 Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af55516e-0a3d-4fd7-8f43-0fa158192460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 512)  # MountainCar-v0 has 2 state dimensions\n",
    "        self.fc2 = nn.Linear(512, 512)  # After many trials, I choose 256 nodes on the hidden layers\n",
    "        self.fc3 = nn.Linear(512, 3)  # 3 actions: left, no movement, right\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Epsilon-greedy action selection\n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0, 2)  # 3 actions for MountainCar-v0\n",
    "        else:\n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73780165-8f35-494f-9915-fd4ae40f510a",
   "metadata": {},
   "source": [
    "# 5. Define the Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0e0608-2eb7-436d-a9cd-55fcbb06460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory, optimizer):\n",
    "    for i in range(10):\n",
    "        s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
    "\n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1, a)\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b917415-415d-4d42-93ea-fc6184b0052f",
   "metadata": {},
   "source": [
    "# 6. Define the Reward Shaping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0111d8-1482-46cc-9fc7-4b55c2d1ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the default -1 reward, I was not able to achieve best learning strategy.\n",
    "# Therefore, after many trials, I added and/or modified the reward considering the car position and velocity.\n",
    "\n",
    "def compute_shaped_reward(car_position, previous_position, velocity, done):\n",
    "    reward = -1  # Default time step penalty\n",
    "\n",
    "    # Reward progress to the right\n",
    "    reward += (car_position - previous_position) * 10  # Scale to emphasize progress\n",
    "    \n",
    "    # Adding velocity for better shaping\n",
    "    reward += abs(velocity)\n",
    "\n",
    "    # Reward for reaching the flag (goal)\n",
    "    if done and car_position >= 0.5:\n",
    "        reward += 100\n",
    "\n",
    "    # Additional reward for crossing a high position threshold\n",
    "    if car_position > 0.5:\n",
    "        reward += 50\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb1f86-a653-44d3-ad8c-c87393be32f3",
   "metadata": {},
   "source": [
    "# 7. Define the DQN Function and save the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28659c87-270c-4196-9232-424b7412b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN for MountainCar-v0\n",
    "\n",
    "def DQN():\n",
    "    env = gym.make('MountainCar-v0', render_mode=\"rgb_array\")\n",
    "    q = Qnet()\n",
    "    q_target = Qnet()\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    memory = ReplayBuffer()\n",
    "\n",
    "    print_interval = 100\n",
    "    score = 0.0  \n",
    "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "\n",
    "    for n_epi in range(max_episodes):\n",
    "        epsilon = max(0.01, 0.9 - 0.01*(n_epi/100))  # Linear annealing from 8% to 1%\n",
    "        s, _ = env.reset()\n",
    "        done = False\n",
    "        previous_position = -1.2  # Initial position of the car\n",
    "\n",
    "        while not done:\n",
    "            a = q.sample_action(torch.tensor(s).float(), epsilon)\n",
    "            s_prime, _, done, truncated, info = env.step(a)\n",
    "            velocity = s_prime[1]  # Get the car's velocity\n",
    "            car_position = s_prime[0]  # Get the car's position\n",
    "            \n",
    "            # Compute shaped reward\n",
    "            r = compute_shaped_reward(car_position, previous_position, velocity, done)\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            memory.put((s, a, r, s_prime, done_mask))\n",
    "            s = s_prime\n",
    "            score += r\n",
    "            previous_position = car_position\n",
    "\n",
    "            if done or truncated:\n",
    "                break\n",
    "\n",
    "        if memory.size() > 2000:\n",
    "            train(q, q_target, memory, optimizer)\n",
    "\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "            print(\"n_episode :{}, avg score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "                  n_epi, score/print_interval, memory.size(), epsilon*100))\n",
    "            score = 0.0\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(q.state_dict(), 'dqn_model.pth')\n",
    "    print(\"Model saved to 'dqn_model.pth'\")\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9efab3a-2845-439d-b962-e83001451d71",
   "metadata": {},
   "source": [
    "# 8. Run the DQN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8582933d-16b4-466b-906b-3c8db398e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/sc2d8gc97c367tf6p8w4yp300000gn/T/ipykernel_1393/848517094.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :100, avg score : -194.2, n_buffer : 20200, eps : 89.0%\n",
      "n_episode :200, avg score : -192.0, n_buffer : 40200, eps : 88.0%\n",
      "n_episode :300, avg score : -192.0, n_buffer : 50000, eps : 87.0%\n",
      "n_episode :400, avg score : -192.2, n_buffer : 50000, eps : 86.0%\n",
      "n_episode :500, avg score : -192.0, n_buffer : 50000, eps : 85.0%\n",
      "n_episode :600, avg score : -192.0, n_buffer : 50000, eps : 84.0%\n",
      "n_episode :700, avg score : -192.0, n_buffer : 50000, eps : 83.0%\n",
      "n_episode :800, avg score : -191.9, n_buffer : 50000, eps : 82.0%\n",
      "n_episode :900, avg score : -191.9, n_buffer : 50000, eps : 81.0%\n",
      "n_episode :1000, avg score : -191.9, n_buffer : 50000, eps : 80.0%\n",
      "n_episode :1100, avg score : -191.9, n_buffer : 50000, eps : 79.0%\n",
      "n_episode :1200, avg score : -191.8, n_buffer : 50000, eps : 78.0%\n",
      "n_episode :1300, avg score : -192.0, n_buffer : 50000, eps : 77.0%\n",
      "n_episode :1400, avg score : -191.6, n_buffer : 50000, eps : 76.0%\n",
      "n_episode :1500, avg score : -191.8, n_buffer : 50000, eps : 75.0%\n",
      "n_episode :1600, avg score : -191.7, n_buffer : 50000, eps : 74.0%\n",
      "n_episode :1700, avg score : -191.9, n_buffer : 50000, eps : 73.0%\n",
      "n_episode :1800, avg score : -191.7, n_buffer : 50000, eps : 72.0%\n",
      "n_episode :1900, avg score : -191.8, n_buffer : 50000, eps : 71.0%\n",
      "n_episode :2000, avg score : -191.6, n_buffer : 50000, eps : 70.0%\n",
      "n_episode :2100, avg score : -191.6, n_buffer : 50000, eps : 69.0%\n",
      "n_episode :2200, avg score : -191.7, n_buffer : 50000, eps : 68.0%\n",
      "n_episode :2300, avg score : -191.6, n_buffer : 50000, eps : 67.0%\n",
      "n_episode :2400, avg score : -191.6, n_buffer : 50000, eps : 66.0%\n",
      "n_episode :2500, avg score : -191.4, n_buffer : 50000, eps : 65.0%\n",
      "n_episode :2600, avg score : -191.6, n_buffer : 50000, eps : 64.0%\n",
      "n_episode :2700, avg score : -191.4, n_buffer : 50000, eps : 63.0%\n",
      "n_episode :2800, avg score : -191.4, n_buffer : 50000, eps : 62.0%\n",
      "n_episode :2900, avg score : -191.5, n_buffer : 50000, eps : 61.0%\n",
      "n_episode :3000, avg score : -191.4, n_buffer : 50000, eps : 60.0%\n",
      "n_episode :3100, avg score : -191.5, n_buffer : 50000, eps : 59.0%\n",
      "n_episode :3200, avg score : -191.6, n_buffer : 50000, eps : 58.0%\n",
      "n_episode :3300, avg score : -191.7, n_buffer : 50000, eps : 57.0%\n",
      "n_episode :3400, avg score : -191.1, n_buffer : 50000, eps : 56.0%\n",
      "n_episode :3500, avg score : -191.6, n_buffer : 50000, eps : 55.0%\n",
      "n_episode :3600, avg score : -191.3, n_buffer : 50000, eps : 54.0%\n",
      "n_episode :3700, avg score : -191.5, n_buffer : 50000, eps : 53.0%\n",
      "n_episode :3800, avg score : -191.5, n_buffer : 50000, eps : 52.0%\n",
      "n_episode :3900, avg score : -191.4, n_buffer : 50000, eps : 51.0%\n",
      "n_episode :4000, avg score : -191.4, n_buffer : 50000, eps : 50.0%\n",
      "n_episode :4100, avg score : -191.1, n_buffer : 50000, eps : 49.0%\n",
      "n_episode :4200, avg score : -191.3, n_buffer : 50000, eps : 48.0%\n",
      "n_episode :4300, avg score : -191.9, n_buffer : 50000, eps : 47.0%\n",
      "n_episode :4400, avg score : -187.4, n_buffer : 50000, eps : 46.0%\n",
      "n_episode :4500, avg score : -180.2, n_buffer : 50000, eps : 45.0%\n",
      "n_episode :4600, avg score : -191.0, n_buffer : 50000, eps : 44.0%\n",
      "n_episode :4700, avg score : -183.5, n_buffer : 50000, eps : 43.0%\n",
      "n_episode :4800, avg score : -179.4, n_buffer : 50000, eps : 42.0%\n",
      "n_episode :4900, avg score : -183.1, n_buffer : 50000, eps : 41.0%\n",
      "n_episode :5000, avg score : -179.3, n_buffer : 50000, eps : 40.0%\n",
      "n_episode :5100, avg score : -175.1, n_buffer : 50000, eps : 39.0%\n",
      "n_episode :5200, avg score : -180.6, n_buffer : 50000, eps : 38.0%\n",
      "n_episode :5300, avg score : -181.7, n_buffer : 50000, eps : 37.0%\n",
      "n_episode :5400, avg score : -176.0, n_buffer : 50000, eps : 36.0%\n",
      "n_episode :5500, avg score : -178.7, n_buffer : 50000, eps : 35.0%\n",
      "n_episode :5600, avg score : -181.7, n_buffer : 50000, eps : 34.0%\n",
      "n_episode :5700, avg score : -181.8, n_buffer : 50000, eps : 33.0%\n",
      "n_episode :5800, avg score : -182.7, n_buffer : 50000, eps : 32.0%\n",
      "n_episode :5900, avg score : -183.0, n_buffer : 50000, eps : 31.0%\n",
      "n_episode :6000, avg score : -179.4, n_buffer : 50000, eps : 30.0%\n",
      "n_episode :6100, avg score : -185.0, n_buffer : 50000, eps : 29.0%\n",
      "n_episode :6200, avg score : -189.8, n_buffer : 50000, eps : 28.0%\n",
      "n_episode :6300, avg score : -189.8, n_buffer : 50000, eps : 27.0%\n",
      "n_episode :6400, avg score : -186.0, n_buffer : 50000, eps : 26.0%\n",
      "n_episode :6500, avg score : -188.0, n_buffer : 50000, eps : 25.0%\n",
      "n_episode :6600, avg score : -184.4, n_buffer : 50000, eps : 24.0%\n",
      "n_episode :6700, avg score : -186.1, n_buffer : 50000, eps : 23.0%\n",
      "n_episode :6800, avg score : -185.8, n_buffer : 50000, eps : 22.0%\n",
      "n_episode :6900, avg score : -185.3, n_buffer : 50000, eps : 21.0%\n",
      "n_episode :7000, avg score : -180.7, n_buffer : 50000, eps : 20.0%\n",
      "n_episode :7100, avg score : -183.9, n_buffer : 50000, eps : 19.0%\n",
      "n_episode :7200, avg score : -187.1, n_buffer : 50000, eps : 18.0%\n",
      "n_episode :7300, avg score : -183.1, n_buffer : 50000, eps : 17.0%\n",
      "n_episode :7400, avg score : -180.5, n_buffer : 50000, eps : 16.0%\n",
      "n_episode :7500, avg score : -182.8, n_buffer : 50000, eps : 15.0%\n",
      "n_episode :7600, avg score : -183.7, n_buffer : 50000, eps : 14.0%\n",
      "n_episode :7700, avg score : -186.7, n_buffer : 50000, eps : 13.0%\n",
      "n_episode :7800, avg score : -175.7, n_buffer : 50000, eps : 12.0%\n",
      "n_episode :7900, avg score : -178.8, n_buffer : 50000, eps : 11.0%\n",
      "n_episode :8000, avg score : -176.9, n_buffer : 50000, eps : 10.0%\n",
      "n_episode :8100, avg score : -164.1, n_buffer : 50000, eps : 9.0%\n",
      "n_episode :8200, avg score : -162.6, n_buffer : 50000, eps : 8.0%\n",
      "n_episode :8300, avg score : -149.1, n_buffer : 50000, eps : 7.0%\n",
      "n_episode :8400, avg score : -168.1, n_buffer : 50000, eps : 6.0%\n",
      "n_episode :8500, avg score : -155.8, n_buffer : 50000, eps : 5.0%\n",
      "n_episode :8600, avg score : -166.3, n_buffer : 50000, eps : 4.0%\n",
      "n_episode :8700, avg score : -141.7, n_buffer : 50000, eps : 3.0%\n",
      "n_episode :8800, avg score : -139.2, n_buffer : 50000, eps : 2.0%\n",
      "n_episode :8900, avg score : -140.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9000, avg score : -122.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9100, avg score : -149.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9200, avg score : -171.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9300, avg score : -155.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9400, avg score : -180.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9500, avg score : -174.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9600, avg score : -171.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9700, avg score : -180.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9800, avg score : -177.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :9900, avg score : -182.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10000, avg score : -169.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10100, avg score : -170.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10200, avg score : -160.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10300, avg score : -167.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10400, avg score : -152.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10500, avg score : -160.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10600, avg score : -157.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10700, avg score : -128.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10800, avg score : -128.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :10900, avg score : -125.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11000, avg score : -127.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11100, avg score : -134.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11200, avg score : -114.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11300, avg score : -114.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11400, avg score : -112.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11500, avg score : -44.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11600, avg score : -55.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11700, avg score : -57.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11800, avg score : -43.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :11900, avg score : -12.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12000, avg score : -22.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12100, avg score : -42.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12200, avg score : -36.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12300, avg score : -39.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12400, avg score : -43.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12500, avg score : -16.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12600, avg score : -19.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12700, avg score : -27.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12800, avg score : -27.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :12900, avg score : -13.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13000, avg score : 12.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13100, avg score : -11.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13200, avg score : -36.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13300, avg score : -29.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13400, avg score : -19.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13500, avg score : -34.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13600, avg score : -3.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13700, avg score : -15.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13800, avg score : -13.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :13900, avg score : -11.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14000, avg score : 4.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14100, avg score : 4.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14200, avg score : 0.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14300, avg score : 29.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14400, avg score : 32.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14500, avg score : 15.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14600, avg score : 37.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14700, avg score : 36.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14800, avg score : 39.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :14900, avg score : 45.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15000, avg score : 37.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15100, avg score : 23.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15200, avg score : 50.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15300, avg score : 45.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15400, avg score : 46.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15500, avg score : 41.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15600, avg score : 60.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15700, avg score : 35.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15800, avg score : 54.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :15900, avg score : 51.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16000, avg score : 40.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16100, avg score : 40.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16200, avg score : 39.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16300, avg score : 49.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16400, avg score : 39.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16500, avg score : 41.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16600, avg score : 40.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16700, avg score : 50.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16800, avg score : 45.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :16900, avg score : 47.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17000, avg score : 23.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17100, avg score : 17.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17200, avg score : 0.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17300, avg score : 5.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17400, avg score : 21.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17500, avg score : 15.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17600, avg score : 0.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17700, avg score : -2.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17800, avg score : 22.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :17900, avg score : 27.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18000, avg score : 37.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18100, avg score : 29.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18200, avg score : 35.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18300, avg score : 27.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18400, avg score : 37.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18500, avg score : 35.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18600, avg score : 42.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18700, avg score : 50.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18800, avg score : 50.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :18900, avg score : 57.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19000, avg score : 45.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19100, avg score : 59.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19200, avg score : 44.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19300, avg score : 52.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19400, avg score : 42.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19500, avg score : 41.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19600, avg score : 31.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19700, avg score : 2.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19800, avg score : 1.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :19900, avg score : 2.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20000, avg score : 1.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20100, avg score : 3.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20200, avg score : -14.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20300, avg score : -10.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20400, avg score : -9.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20500, avg score : -28.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20600, avg score : -22.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20700, avg score : -30.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20800, avg score : -69.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :20900, avg score : -51.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21000, avg score : -64.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21100, avg score : -50.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21200, avg score : -44.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21300, avg score : -50.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21400, avg score : -10.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21500, avg score : -1.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21600, avg score : 16.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21700, avg score : -26.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21800, avg score : -50.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :21900, avg score : -25.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22000, avg score : -37.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22100, avg score : -23.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22200, avg score : -30.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22300, avg score : -10.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22400, avg score : -21.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22500, avg score : 1.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22600, avg score : 13.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22700, avg score : 30.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22800, avg score : 7.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :22900, avg score : 16.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23000, avg score : 19.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23100, avg score : -4.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23200, avg score : -86.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23300, avg score : -71.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23400, avg score : -77.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23500, avg score : -77.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23600, avg score : -74.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23700, avg score : -77.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23800, avg score : -60.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :23900, avg score : -14.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24000, avg score : 5.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24100, avg score : 18.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24200, avg score : 16.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24300, avg score : 2.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24400, avg score : -1.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24500, avg score : 11.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24600, avg score : 34.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24700, avg score : 36.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24800, avg score : 32.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :24900, avg score : -39.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25000, avg score : 37.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25100, avg score : 29.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25200, avg score : 45.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25300, avg score : 41.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25400, avg score : 49.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25500, avg score : 33.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25600, avg score : 16.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25700, avg score : 41.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25800, avg score : 35.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :25900, avg score : 31.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26000, avg score : 22.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26100, avg score : 11.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26200, avg score : 24.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26300, avg score : 7.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26400, avg score : -56.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26500, avg score : -29.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26600, avg score : 11.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26700, avg score : -2.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26800, avg score : 14.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :26900, avg score : 2.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27000, avg score : -13.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27100, avg score : 13.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27200, avg score : -30.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27300, avg score : -45.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27400, avg score : -20.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27500, avg score : -19.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27600, avg score : -5.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27700, avg score : 12.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27800, avg score : -14.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :27900, avg score : -14.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28000, avg score : -13.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28100, avg score : 9.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28200, avg score : -0.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28300, avg score : -2.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28400, avg score : -5.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28500, avg score : 15.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28600, avg score : 25.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28700, avg score : 14.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28800, avg score : 14.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :28900, avg score : 28.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29000, avg score : 23.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29100, avg score : 26.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29200, avg score : 23.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29300, avg score : 34.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29400, avg score : 36.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29500, avg score : 26.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29600, avg score : 40.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29700, avg score : 30.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29800, avg score : 34.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :29900, avg score : 26.9, n_buffer : 50000, eps : 1.0%\n",
      "Model saved to 'dqn_model.pth'\n"
     ]
    }
   ],
   "source": [
    "DQN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12c3d1-858f-4b4e-95dc-df169f95e297",
   "metadata": {},
   "source": [
    "# 9. Load the Pre-Trained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5d3b13-e986-49a9-a7f7-c8c0e5dcaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(filepath):\n",
    "    q = Qnet()  # Initialize the Q-network architecture\n",
    "    q.load_state_dict(torch.load(filepath))  # Load the saved weights\n",
    "    q.eval()  # Set the model to evaluation mode\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26c8b1-b7de-4484-8856-f8a59639c077",
   "metadata": {},
   "source": [
    "# 10. Test the Model with Epsilon Zero (i.e Greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b9db5b-1308-4e98-a049-3aa5af55a551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with score: 92.0\n",
      "Episode 2 finished with score: 158.0\n",
      "Episode 3 finished with score: 157.0\n",
      "Episode 4 finished with score: 162.0\n",
      "Episode 5 finished with score: 102.0\n",
      "Episode 6 finished with score: 160.0\n",
      "Episode 7 finished with score: 161.0\n",
      "Episode 8 finished with score: 103.0\n",
      "Episode 9 finished with score: 89.0\n",
      "Episode 10 finished with score: 163.0\n"
     ]
    }
   ],
   "source": [
    "# Test the model after loading\n",
    "def test_trained_model(q, n_episodes=10):\n",
    "    env = gym.make('MountainCar-v0', render_mode=\"human\")  # Use 'human' to visualize the environment\n",
    "    for episode in range(n_episodes):\n",
    "        s, _ = env.reset()\n",
    "        done = False\n",
    "        score = 0.0\n",
    "        \n",
    "        while not done:\n",
    "            a = q.sample_action(torch.tensor(s).float(), epsilon=0)  # Set epsilon to 0 for testing\n",
    "            s, _, done, truncated, info = env.step(a)\n",
    "            score += 1  # Increment score for each time step\n",
    "            \n",
    "            if done or truncated:\n",
    "                print(f\"Episode {episode + 1} finished with score: {score}\")\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "q_loaded = load_trained_model('dqn_model.pth')\n",
    "test_trained_model(q_loaded, n_episodes=10)  # Test the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960a1af-e05a-4935-882f-ec9629cb0e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
